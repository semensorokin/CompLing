{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "morph = MorphAnalyzer()\n",
    "stops = set(stopwords.words('russian'))\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "stops = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "PATH_TO_DATA = '../ru_kw_eval_datasets-master/data'\n",
    "files = [os.path.join(PATH_TO_DATA, file) for file in os.listdir(PATH_TO_DATA)]\n",
    "data = pd.concat([pd.read_json(file, lines=True) for file in files][:1], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_data = data[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('articals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "def evaluate(true_kws, predicted_kws):\n",
    "    assert len(true_kws) == len(predicted_kws)\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    jaccards = []\n",
    "    \n",
    "    for i in range(len(true_kws)):\n",
    "        true_kw = set(true_kws[i])\n",
    "        predicted_kw = set(predicted_kws[i])\n",
    "        \n",
    "        tp = len(true_kw & predicted_kw)\n",
    "        union = len(true_kw | predicted_kw)\n",
    "        fp = len(predicted_kw - true_kw)\n",
    "        fn = len(true_kw - predicted_kw)\n",
    "        \n",
    "        if (tp+fp) == 0:\n",
    "            prec = 0\n",
    "        else:\n",
    "            prec = tp / (tp + fp)\n",
    "        \n",
    "        if (tp+fn) == 0:\n",
    "            rec = 0\n",
    "        else:\n",
    "            rec = tp / (tp + fn)\n",
    "        if (prec+rec) == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = (2*(prec*rec))/(prec+rec)\n",
    "            \n",
    "        jac = tp / union\n",
    "        \n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1s.append(f1)\n",
    "        jaccards.append(jac)\n",
    "    print('Precision - ', round(np.mean(precisions), 2))\n",
    "    print('Recall - ', round(np.mean(recalls), 2))\n",
    "    print('F1 - ', round(np.mean(f1s), 2))\n",
    "    print('Jaccard - ', round(np.mean(jaccards), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization \n",
    "def normalize(text):\n",
    "    \n",
    "    words = [word.strip(punct) for word in text.lower().split()]\n",
    "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ''\n",
    "for i in part_data.content.tolist():\n",
    "    text_data+=i\n",
    "    text_data+=' '\n",
    "text_data = text_data.replace('\\n', '. ')\n",
    "text_data = text_data.replace('.. ', '. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Неизвестные помещения в гробнице Тутанхамона. Самой обсуждаемой египетской историей 2016 года, котор'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokenize_list = sent_tokenize(text_data)\n",
    "clear_sents=[]\n",
    "for i in sent_tokenize_list:\n",
    "    clear_sent = []\n",
    "    clear_sent = normalize(i)\n",
    "    clear_sents.append(clear_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "simple_model = gensim.models.FastText(clear_sents, size=100, window=5,\n",
    "                                      min_count=0, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semen/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "def word_to_vec(split_text):\n",
    "    return [simple_model[i] for i in split_text]\n",
    "\n",
    "part_data['norm_text'] = part_data.content.apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>keywords</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>norm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Неизвестные помещения в гробнице Тутанхамона\\n...</td>\n",
       "      <td>[без политики, египет, исследование, наука, ис...</td>\n",
       "      <td>О самых значимых открытиях в египетской археол...</td>\n",
       "      <td>Дневник строителя пирамиды и ноги красавицы Не...</td>\n",
       "      <td>https://russian.rt.com/science/article/340861-...</td>\n",
       "      <td>[неизвестный, помещение, гробница, тутанхамон,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В Нижнем Новгороде ФСБ нейтрализовала преступн...</td>\n",
       "      <td>[владимир путин, выборы президента россии 2018...</td>\n",
       "      <td>В Нижнем Новгороде нейтрализован сторонник ИГ*...</td>\n",
       "      <td>«Оказал сопротивление и был нейтрализован»: в ...</td>\n",
       "      <td>https://russian.rt.com/russia/article/476044-f...</td>\n",
       "      <td>[нижний, новгород, фсб, нейтрализовать, престу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Американский лидер Дональд Трамп продолжает бо...</td>\n",
       "      <td>[в мире, дональд трамп, сми, сша, телевидение,...</td>\n",
       "      <td>Президент США Дональд Трамп грозит отзывом лиц...</td>\n",
       "      <td>«За попытки дискредитировать и очернить»: Трам...</td>\n",
       "      <td>https://russian.rt.comhttps://russian.rt.com/w...</td>\n",
       "      <td>[американский, лидер, дональд, трамп, продолжа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Украина столкнулась с новым скандалом при орга...</td>\n",
       "      <td>[деньги, евровидение, киев, музыка, скандал, у...</td>\n",
       "      <td>Европейский вещательный союз недоволен темпами...</td>\n",
       "      <td>Песня прощается с тобой: почему Украина не усп...</td>\n",
       "      <td>https://russian.rt.com/ussr/article/336895-ukr...</td>\n",
       "      <td>[украина, столкнуться, новый, скандал, организ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Комиссия Совфеда по защите госсуверенитета рек...</td>\n",
       "      <td>[google, rt, youtube, в мире, россия, сми, сша...</td>\n",
       "      <td>Профильные ведомства должны подготовить предло...</td>\n",
       "      <td>«Активное давление»: Совфед рекомендовал разра...</td>\n",
       "      <td>https://russian.rt.com/world/article/436876-go...</td>\n",
       "      <td>[комиссия, совфеда, защита, госсуверенитет, ре...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Неизвестные помещения в гробнице Тутанхамона\\n...   \n",
       "1  В Нижнем Новгороде ФСБ нейтрализовала преступн...   \n",
       "2  Американский лидер Дональд Трамп продолжает бо...   \n",
       "3  Украина столкнулась с новым скандалом при орга...   \n",
       "4  Комиссия Совфеда по защите госсуверенитета рек...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [без политики, египет, исследование, наука, ис...   \n",
       "1  [владимир путин, выборы президента россии 2018...   \n",
       "2  [в мире, дональд трамп, сми, сша, телевидение,...   \n",
       "3  [деньги, евровидение, киев, музыка, скандал, у...   \n",
       "4  [google, rt, youtube, в мире, россия, сми, сша...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  О самых значимых открытиях в египетской археол...   \n",
       "1  В Нижнем Новгороде нейтрализован сторонник ИГ*...   \n",
       "2  Президент США Дональд Трамп грозит отзывом лиц...   \n",
       "3  Европейский вещательный союз недоволен темпами...   \n",
       "4  Профильные ведомства должны подготовить предло...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Дневник строителя пирамиды и ноги красавицы Не...   \n",
       "1  «Оказал сопротивление и был нейтрализован»: в ...   \n",
       "2  «За попытки дискредитировать и очернить»: Трам...   \n",
       "3  Песня прощается с тобой: почему Украина не усп...   \n",
       "4  «Активное давление»: Совфед рекомендовал разра...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://russian.rt.com/science/article/340861-...   \n",
       "1  https://russian.rt.com/russia/article/476044-f...   \n",
       "2  https://russian.rt.comhttps://russian.rt.com/w...   \n",
       "3  https://russian.rt.com/ussr/article/336895-ukr...   \n",
       "4  https://russian.rt.com/world/article/436876-go...   \n",
       "\n",
       "                                           norm_text  \n",
       "0  [неизвестный, помещение, гробница, тутанхамон,...  \n",
       "1  [нижний, новгород, фсб, нейтрализовать, престу...  \n",
       "2  [американский, лидер, дональд, трамп, продолжа...  \n",
       "3  [украина, столкнуться, новый, скандал, организ...  \n",
       "4  [комиссия, совфеда, защита, госсуверенитет, ре...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23081, 23073)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(part_data.norm_text.sum())), len(simple_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semen/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/home/semen/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "part_data['text_to_vec'] = part_data.norm_text.apply(word_to_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1149"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(part_data.text_to_vec[:1].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1149"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(part_data.norm_text[:1].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.array(part_data.text_to_vec[:1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy\n",
    "from gensim.models import word2vec\n",
    "from nltk.corpus import stopwords\n",
    "from numpy import *\n",
    "\n",
    "def find_kw(trainData):\n",
    "    trainData = numpy.array(trainData)\n",
    "    # calculate cosine similarity matrix to use in pagerank algorithm for dense matrix, it is not\n",
    "    # fast for sparse matrix\n",
    "    # sim_matrix = 1-pairwise_distances(trainData, metric=\"cosine\")\n",
    "\n",
    "    # similarity matrix, it is 30 times faster for sparse matrix\n",
    "    # replace this with A.dot(A.T).todense() for sparse representation\n",
    "    similarity = numpy.dot(trainData, trainData.T)\n",
    "\n",
    "    # squared magnitude of preference vectors (number of occurrences)\n",
    "    square_mag = numpy.diag(similarity)\n",
    "\n",
    "    # inverse squared magnitude\n",
    "    inv_square_mag = 1 / square_mag\n",
    "\n",
    "    # if it doesn't occur, set it's inverse magnitude to zero (instead of inf)\n",
    "    inv_square_mag[numpy.isinf(inv_square_mag)] = 0\n",
    "\n",
    "    # inverse of the magnitude\n",
    "    inv_mag = numpy.sqrt(inv_square_mag)\n",
    "\n",
    "    # cosine similarity (elementwise multiply by inverse magnitudes)\n",
    "    cosine = similarity * inv_mag\n",
    "    cosine = cosine.T * inv_mag\n",
    "\n",
    "\n",
    "    # pagerank powermethod\n",
    "    def powerMethod(A, x0, m, iter):\n",
    "        n = A.shape[1]\n",
    "        delta = m * (array([1] * n, dtype='float64') / n)\n",
    "        for i in range(iter):\n",
    "            x0 = dot((1 - m), dot(A, x0)) + delta\n",
    "        return x0\n",
    "\n",
    "\n",
    "    n = cosine.shape[1]  # A is n x n\n",
    "    m = 0.15\n",
    "    x0 = [1] * n\n",
    "\n",
    "    pagerank_values = powerMethod(cosine, x0, m, 130)\n",
    "\n",
    "    srt = numpy.argsort(pagerank_values)\n",
    "    a = srt[0:20]\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semen/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ppp=part_data[:15]\n",
    "ppp['kw'] = ppp.text_to_vec.apply(find_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.03\n",
      "Recall -  0.07\n",
      "F1 -  0.04\n",
      "Jaccard -  0.02\n"
     ]
    }
   ],
   "source": [
    "evaluate(ppp.keywords, all_key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "da =ppp.norm_text.tolist()\n",
    "all_key_words=[]\n",
    "for ind,i in enumerate(ppp.kw.tolist()):\n",
    "    k_words=[]\n",
    "    for j in i:\n",
    "        k_words.append(da[ind][j])\n",
    "    all_key_words.append(k_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_key_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter words only one vxojdenie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
